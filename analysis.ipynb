{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0104cb88-1586-4bc0-9997-65df19481697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/env/python3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fca43eb-64ce-4a8d-9871-7e76ca22fba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the necessary modules \n",
    "import os \n",
    "import cv2 \n",
    "import imutils \n",
    "import pickle \n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from imutils import paths\n",
    "from imutils.paths import list_images\n",
    "import matplotlib.pyplot as plt \n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD \n",
    "from tensorflow.keras.preprocessing.image import img_to_array \n",
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from sklearn.model_selection import  train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, MultiLabelBinarizer, OneHotEncoder  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.layers import Flatten, Dropout  \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization  \n",
    "from tensorflow.keras.layers import MaxPooling2D, SeparableConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d07caa12-d4f4-4695-8999-57fd9a8995dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e204a740-8d2c-4d7b-aca8-800bfc22dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the path to the image directory \n",
    "imageDataSet = \"dataset/\"\n",
    "\n",
    "# Initialize the initial learning rate, number of epochs to train \n",
    "# for and batch size \n",
    "INIT_LR = 1e-3; \n",
    "EPOCHS = 2\n",
    "BS = 8 \n",
    "\n",
    "# Setting the data, and labels \n",
    "data = []; \n",
    "labels = []; \n",
    "\n",
    "# Grab the list of images in our dataset directory, then \n",
    "# initialize the list of data, and class images \n",
    "imagePaths = list(list_images(imageDataSet)) \n",
    "\n",
    "# Loop over the image paths \n",
    "for imagePath in imagePaths: \n",
    "    # Extract the class label from the filename \n",
    "    label = imagePath.split(\"/\")[-2] \n",
    "    \n",
    "    # Load the image, swap color channels, and resize it to be a \n",
    "    # fixed 224 X 224 pixel whilte ignoreing aspect ratio \n",
    "    image = cv2.imread(imagePath) \n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image = cv2.resize(image, (224, 224)) \n",
    "    \n",
    "    # Update the data and labels lists, respectively \n",
    "    data.append(image) \n",
    "    labels.append(label) \n",
    "    \n",
    "# Convert the data and labels to numpy arrays while scaling \n",
    "# the pixel intensities to the range [0 -1] \n",
    "data = np.array(data) / 255.0 \n",
    "labels = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56627a0f-6fe3-480a-91c5-b8e9831a4e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform one hot encoding on the labels \n",
    "lb = MultiLabelBinarizer()\n",
    "labels = lb.fit_transform(labels) \n",
    "encodedLabels = to_categorical(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536a69ac-b8c2-4b6a-9102-24db4c150193",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1500, 224, 224, 3)\n",
      "Output Shape: (1500, 10)\n"
     ]
    }
   ],
   "source": [
    "# Displaying the shape of the input and output variables \n",
    "print(f'Input Shape: {data.shape}') \n",
    "print(f'Output Shape: {labels.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a159c7fc-0bf1-4430-8024-6153d2249aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lb.classes_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdfca91-29f5-41ae-9186-d1cd561b8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data into training and testing splits uing 80% \n",
    "# of the data for training and the remaining 20% for testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(data, encodedLabels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ca6f11-bab2-4e66-a999-0083c7c85baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 23:40:05.869765: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 23:40:06.154082: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " separable_conv2d (Separable  (None, 224, 224, 32)     203       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 224, 224, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 112, 112, 64)      51264     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 112, 112, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      102464    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 112, 112, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 128)       204928    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 56, 56, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 128)       409728    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 56, 56, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 56, 56, 128)      19712     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 56, 56, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               25690368  \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,484,437\n",
      "Trainable params: 26,482,837\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbonu/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the number of epochs to train for, initial learning rate \n",
    "# batch size, and image dimensions \n",
    "# epochs = 100\n",
    "epochs = 2\n",
    "ini_lr = 1e-3 \n",
    "bs = 32\n",
    "dim = (224, 224, 3) \n",
    "# cov = (3, 3) \n",
    "cov = (5, 5)\n",
    "\n",
    "# Building the neural network model \n",
    "class SmallerVGGNet:\n",
    "    @staticmethod \n",
    "    # Creating a function for building the model \n",
    "    def build_model(width, height, depth, classes, finalAct=\"softmax\"):\n",
    "        # Initilize the model along with the input shape to be the \n",
    "        # channels last, and the channels dimensions itself \n",
    "        model = Sequential() \n",
    "        input_shape = (height, width, depth)\n",
    "        # input_shape = (height, width)\n",
    "        chan_dim = -1 \n",
    "      \n",
    "        # If we are using \"channels first\", update the input shape \n",
    "        # And channels dimension \n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            input_shape = (height, width, depth)\n",
    "            # input_shape = (height, width)\n",
    "            chan_dim = 1\n",
    "            \n",
    "        # Convolution to Rectified to Maxpool2D \n",
    "        model.add(SeparableConv2D(32, cov, padding=\"same\", input_shape=input_shape)) \n",
    "        model.add(Activation(\"relu\")) \n",
    "        model.add(BatchNormalization(axis=chan_dim)) \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "        model.add(Dropout(0.25)) \n",
    "        \n",
    "        # Convolution to Rectified to MaxPool2D \n",
    "        model.add(Conv2D(64, cov, padding=\"same\")) \n",
    "        model.add(Activation(\"relu\")) \n",
    "        model.add(BatchNormalization(axis=chan_dim)) \n",
    "        model.add(Conv2D(64, cov, padding=\"same\")) \n",
    "        model.add(Activation(\"relu\")) \n",
    "        model.add(BatchNormalization(axis=chan_dim)) \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "        model.add(Dropout(0.25)) \n",
    "        \n",
    "        # Convolution to Rectified then MaxPool2D \n",
    "        model.add(Conv2D(128, cov, padding=\"same\")) \n",
    "        model.add(Activation(\"relu\")) \n",
    "        model.add(BatchNormalization(axis=chan_dim)) \n",
    "        model.add(Conv2D(128, cov, padding=\"same\")) \n",
    "        model.add(Activation(\"relu\")) \n",
    "        model.add(BatchNormalization(axis=chan_dim)) \n",
    "        model.add(SeparableConv2D(128, cov, padding=\"same\")) \n",
    "        model.add(Activation(\"relu\")) \n",
    "        model.add(BatchNormalization(axis=chan_dim)) \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "        model.add(Dropout(0.25)) \n",
    "        \n",
    "        # First, and only the Fully connected layers then to Rectified linear unit layers \n",
    "        model.add(Flatten()) \n",
    "        model.add(Dense(256)) \n",
    "        model.add(Activation(\"relu\")) \n",
    "        model.add(BatchNormalization()) \n",
    "        model.add(Dropout(0.25)) \n",
    "        \n",
    "        # Softmax classified \n",
    "        model.add(Dense(classes)) \n",
    "        model.add(Activation(finalAct)) \n",
    "        \n",
    "        # Return the constructed neural network \n",
    "        return model \n",
    "    \n",
    "    \n",
    "# Construct the image generator for data augmentation \n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1, \n",
    "                             height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, \n",
    "                             horizontal_flip=True, fill_mode=\"nearest\") \n",
    "\n",
    "# Initialize the model using a sigmoid activation as the final layers in the \n",
    "# Network so we can perfom the classification method \n",
    "model = SmallerVGGNet.build_model(width=dim[0], height=dim[1], depth=dim[2], \n",
    "                                  classes=len(lb.classes_), finalAct=\"sigmoid\") \n",
    "\n",
    "# Initialze the optimizer \n",
    "opt = Adam(lr=ini_lr, decay=ini_lr / epochs) \n",
    "\n",
    "# Compiling the model \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) \n",
    "\n",
    "# Model summary \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e0e38-470e-482e-b1cb-433279e93427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# Training the model, and generate a weighted file \n",
    "H = model.fit(aug.flow(X_train, y_train, batch_size=bs), validation_data=(X_test, y_test), \n",
    "                        steps_per_epoch=len(X_train) // bs, \n",
    "                        epochs=epochs, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae5b70-6e13-49e7-9d72-d9021a1c262d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c2bbfc1-0fdf-419f-a5ed-76b39e7015e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training daa augmentaion object \n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=15, \n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "# Load the VGG16 network, ensuring the head FC layer sets are left \n",
    "# off \n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, \n",
    "                  input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the \n",
    "# base model \n",
    "headModel = baseModel.output \n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel) \n",
    "headModel = Flatten(name=\"flatten\")(headModel) \n",
    "headModel = Dense(64, activation=\"relu\")(headModel) \n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel) \n",
    "\n",
    "# Place the head FC model on top of the base model \n",
    "model = Model(inputs=baseModel.input, outputs=headModel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3777b6-5b08-4df0-9893-bed158a25468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbonu/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile our model \n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS) \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d7880-da83-432a-ad0a-185c054a967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model \n",
    "H = model.fit_generator(\n",
    "    trainAug.flow(trainX, trainY, batch_size=BS), \n",
    "    steps_per_epoch=len(trainX) // BS, \n",
    "    validation_data=(testX, testY), \n",
    "    validation_steps=len(testX) // BS, \n",
    "    epoch=EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932652c7-8910-4b78-a20a-612f1cdfbdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d5239-0873-4ad6-8595-623e338d9790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9f983-726a-4795-98f8-1c437204bb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
